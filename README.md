# 00.Application of Crystal Graph Neural Network for Spatial Search of Halide Perovskite Potential Energy
Repository for my GNN Benchmark Research for Halide Perovskite


**[계속 수정중인 글입니다.]**

# Graph Neural Network and Its Application for Computational Physics

![Graph Neural Network](https://user-images.githubusercontent.com/76824867/160241710-4e567f9f-7ccc-4bd5-a1f7-212d754fc552.jpeg)

이 연구는 2020년 12월 혹은 2021년 1월 경에 지도교수님께서 내게 보여주셨던 하나의 논문에서 시작되었다.

해당 논문은 **Crystal Graph Convolutional Neural Network**를 최초로 제안하여, Deep Learning을 이용한 결정구조 물질의 물성예측을 시도했던 한 연구에 관한 것이었다. 연구에 사용된 코드를 저자가 Github를 통해 공개했었기 때문에, 그 코드를 Repository에서 다운로드하여 코드분석을 시작했었다. 대략적인 코드 분석에는 한 달 정도의 시간이 소요되었던 것 같다. 

코드는 PyTorch 기반으로 작성되어 있었는데, 당시의 나는 Keras를 주 프레임워크로 사용하여 연구를 해왔기 때문에 Torch에 대해서는 기본적인 수준의 지식밖에 없었다. 결국 코드를 깊게 분석하려면 Torch에 대한 일정 수준의 이해가 필요했고, Torch를 공부하는 기나긴 여정에 들어갔다. 여러가지로 복잡했지만, 결국 대략적인 내용은 다른 딥러닝 프로젝트와 크게 다르지 않았다. 

즉, 데이터를 생성하거나 어딘가에서 받아와서, 전처리하고, 신경망을 모델링하여, 학습 후 성능을 체크하는 것이 전부였다. 다만, 저자는 다양한 딥러닝 Layer와 모델을 직접 작성하였고, 데이터를 전처리하는 다양한 부분이 모두 전형적인 Torch 스타일 또는 저자가 직접 작성한 함수들로 구성되어 있었다. 

현재 시점의 내가 보기에는 그렇게까지 어려운 수준의 코드는 아니지만, Torch를 이제 막 접했던 시점의 내가 보기에는 굉장히 복잡하고 큰 규모의 프로젝트 코드로 보였다. 결국 함수와 클래스, 메서드를 하나하나 의미분석을 하며 코드리뷰를 하게 되었다. 

생각해보면, 아마 이 때가 나의 프로그래밍 경험에서 진지하게 타인의 코드를 분석하기 시작한 첫 사례였던 것 같다. 이전까지는 타인의 코드를 주의깊게 볼 필요가 없었고, 보더라도 인터넷에서 종종 보이는 몇 줄 안 되는 코드였기 때문에 코드분석에 어려움을 느끼는 것이 없었다. 그러나 연구에서 처음으로 경험하게 된, MIT 물리학과 박사과정 학생이 발표한, 그것도 익숙하지 않은 프레임워크로 작성된 물성예측 코드는 정말 인터넷에서 떠도는 코드들과는 차원이 달랐다. 그것들을 완전한 수준으로 이해하는 데에는 내 생각보다 훨씬 오랜 시간이 걸렸다. 그리고 그 과정에서 정말 많은 것을 배웠다고 생각한다.

지금의 나는 CGCNN을 비롯하여 다양한 수준의 딥러닝 모델들을 나름대로 잘 이해할 정도의 지식은 갖게 되었다고 조심스럽게 생각한다. 그리고 원한다면 적절한 커스텀을 할 수도 있다. 또한, 저자의 코드로부터 수준 높은 코딩스타일에 대한 감각도 익힐 수 있었다. 이제는 해당 연구가 갖고 있는 충분하지 않은 점도 지적할 수 있게 되었다.

이 글에서는, 지금까지 내가 진행해온 CGCNN과 관련된 공부 및 연구의 여정을 기억나는대로 모두 적어보고자 한다. 이 글을 쓰는 목적은 첫번째로 단순한 기록의 목적이고, 두번째로는 대학원생으로서 글쓰기 능력을 향상시키기 위함이다.

다음과 같은 순서로 글을 쓰면 좋을 것 같다.

1. 무엇에 관한 연구인가? 연구에 배경에 관하여
2. 데이터에 관한 설명, 어떤 데이터이고 어떤 특성을 가졌는가? 어디서 받아오는가?
3. 데이터 전처리에 관한 설명
4. 모델링에 관한 설명, Graph Neural Network (GNN) 이란 무엇인가?
5. CGCNN 기존 연구의 전반적인 약점, 개선해야 할 점
6. 내가 진행하는 연구에 대하여, 무엇이 개선되었는가? 무엇을 공부했는가?


## 1. 연구의 배경 (Background of the Research) / 무엇에 관한 연구인가?

연구의 배경에 대해 먼저 설명하자면, 기본적으로 **"물성예측(Prediction of Physical/Chemical Properties)"**을 하기 위함이라고 할 수 있다.

우리 주변의 세계를 보자. 우주는 수많은 **물질(Material)**로 구성되어 있다. 건물들은 온갖 단단한 건축자재들로 이루어져 있다. 종이는 나무를 구성하는 다양한 유기물로부터 만들어진다. 내가 지금 사용 중인 컴퓨터와 모니터, 키보드는 반도체, 공업용 금속, 알루미늄, 플라스틱 등 어떤 도구를 만들기에 적합한 물성을 가진 물질로 만들어져 있다. 눈 앞에 아무것도 없는 공간을 손으로 휘저으면 제대로 지각되기는 어렵지만, 그 공간을 채우고 있던 수많은 공기분자들이 움직일 것이다. 

즉, 우리가 살고 있는 우주는, 행성과 같은 거대한 스케일이 아니라 우리가 살고 있는 일상적인 공간의 스케일에서도, 그 어디에도 진정한 물리적 "진공"은 존재하지 않는다. 모든 것은 물질이며, 모든 공간은 물질로 채워져 있다.

그리고 우리는 살아가면서 이러한 물질을 활용한다. 어떤 물질은 거의 그대로 활용되고 어떤 물질은 그렇지 않다. 예를 들면, 나무에서 과일을 따서 먹는다면, 그것은 특별히 가공과정을 거치지 않고 그대로 활용된 셈이다. 반면 어떤 물질은 그렇지 않다. 만약 당신이 원시적인 생활환경에서 집을 만들고자 한다면, 집을 구성하는 다양한 건축자재들의 원형(raw-material)을 준비해야 할 것이다. 그리고 그 각각에 대한 가공을 해야 할 것이다. 그리고 그것들을 조합하여 집을 만들게 될 것이다.

여기서 중요한 것은, 우리가 어떤 목적을 이루기 위해 주변의 물질을 활용할 때, 특정한 종류의 물질만이 적합하다는 사실이다. 예를 들면, 튼튼한 창고를 만들려고 할 때 당신이 자연스럽게 자재로서 고려하는 것은 근처에 있는 바위, 나무와 같은 단단한 재질의 무언가일 것이다. 창고의 벽을 물렁한 재질로 만든다던가, 혹은 물과 같은 액체로 구성하려는 생각은 애초에 하지도 않을 것이다. 즉, **우리가 물질을 활용할 때는 적합한 물성(Physical Property)을 갖는 물질들만이 필요하다**. 그리고 여기에서 모든 것이 시작된다.

좀 더 구체적으로, 당신이 효율적인 태양전지(Solar Cell)를 개발하는 연구원이라고 하자. 태양전지는 말 그대로 태양으로부터 백색광을 받아 그것으로부터 전기를 생산할 수 있게 도와주는 친환경적인 소자이다. 수십년 동안 태양전지의 효율성을 높이기 위한 다양한 연구가 진행되어 왔으며, 현 시점에서도 다양한 물질이 태양전지의 후보물질로 연구되고 있다. 나는 태양전지를 연구하는 사람은 아니고, 다만 주변에 그런 연구원들이 있어서 어깨너머로 들은 정도에 불과하지만, 태양전지의 효율성을 높이기 위해 연구되는 유망한 후보물질들 중 하나에는 **페로브스카이트(Perovskite)**라는 것이 있다. 화학식으로 말하자면 **ABX3**로 표현되며, 아름다운 결정구조를 갖는 물질군(group)인데, 이것이 최근 몇년동안 태양전지의 효율성을 높이기 위해 사용되는 인기있는 후보물질이라고 한다.

그렇다면 이 분야의 연구원들이 하는 다양한 고민들 중에는 이런 것이 있을 것이다.

> "태양전지의 효율을 높이기 위해서는 중간에 특정한 물리적 성질을 갖는 물질이 들어가주면 좋을 것 같다. 그런데 그런 물성을 갖는 물질구조를 어떻게 찾아내지?"

어떤 물질을 넣고 실험을 했을 때, 원자 레벨에서 물질간의 상호작용이 어떻게 될지 미리 예측하는 것은 매우 어려운 일이고 (아주 불가능하지는 않지만), 이 세상에는 온갖 다양한 구조와 조성을 갖는 물질들이 있다. 이 모든 경우의 수를 일일이 다 확인해가며 연구를 할 수는 없다. 실험물리를 하는 연구원들이 이런 고민을 할 때, 물리학의 다른 분야에서는 또 다른 연구가 진행되고 있었다.


### 계산과학기법 (Computational Physics, DFT)

물질에 대해 정립된 복잡한 양자역학적 이론과 컴퓨터의 연산능력을 이용하여 이론적인 시뮬레이션을 실제 물질에 대해 수행함으로써, 실험을 하지 않고도 대략적으로나마 물질 내부의 복잡한 상호작용을 예측하는 방법이 발전되고 있었다. 

계산과학이라고 불리는 이 분야는, 원자레벨의 세상에서 일어나는 복잡한 상호작용을, 양자역학에 기반한 고체물리학 이론과 컴퓨터의 연산능력을 결합시켜 예측하는 것을 목표로 만들어진 것이었다.

나의 지도교수님의 전문분야이기도 한 이것은, 그 안에 다양한 종류의 세부분야를 갖고 있는데 그 중에서 내가 배우는 것은 **밀도범함수 이론(Density Functional Theory, DFT)**라고 불리는 것이다. 내가 알기로 보통 계산물리학 분야에서는 DFT를 자주 다루고, 계산화학이나 재료분야에서는 관점에 따라 조금씩 다른 방법론을 취한다고 한다. 어쨌든 여기서 DFT는 물질 내부의 양자역학적 상호작용을 계산해낼 수 있는 시뮬레이션 기법 정도로 이해하고 넘어가면 될 것 같다.

자, 그럼 DFT와 같은 기술이 있어서 물질 내부의 상호작용을 (실험을 하지 않고도), 대략적으로 예측할 수 있다고 하자.

그럼 도대체 뭐가 문제일까? 실험물리 연구원들과 이론물리 연구원들이 협업하여 여러가지 물질에 대한 시뮬레이션을 돌리고, 그 중에 괜찮은 결과를 보이는 후보물질들에 대하여 실제 실험으로 검증하면 간단히 끝나는 것이 아닐까? 라고 생각할 수 있다. 

그러나 생각보다 그렇게 쉽지는 않다. 왜냐하면 DFT를 비롯하여 다른 수많은 물질 시뮬레이션 기법의 단점은, 일반적으로 정확도(Accuracy)와 연산시간(Computational Time) 사이의 Trade-off (교환관계)가 성립하기 때문이다. 즉, 물질을 정확하게 계산하려고 할수록, 더 엄격한 조건들이 요구되며 시뮬레이션 시간 또한 급증하게 된다.

여기서는 자세히 언급하지 않고 넘어가지만, 물질의 시뮬레이션은 굉장히 다양한 방식으로 사용자가 조정할 수 있다. DFT 등의 계산과학기법은 보통 상용화된 무료/유료 프레임워크가 존재하여 이들을 이용하면 학부생이라도 시뮬레이션을 하는 것이 어렵지는 않다. 다만, 수많은 시뮬레이션 파라미터들의 정확한 의미를 알기 위해서는, 복잡한 고체물리 이론을 깊게 공부하는 것이 요구되기 때문에, 전문가 수준으로 DFT를 다루고 그 결과까지 제대로 해석하기 위해서는 오랜 세월이 걸린다.

결과적으로 계산과학 기법들조차도 여러가지 한계로 인해 (방대한 연산시간, 이론이 가정하고 있는 계산과학적 가정과 현실의 불일치 등), 가능한 모든 물질조합에 대해 계산하는 것은 불가능했다. 그럼에도 불구하고, 수십년 동안 계산과학 분야의 시뮬레이션 데이터들은 차곡차곡 생성 및 축적되어 왔는데 이것이 오늘날 Deep Learning을 계산물리학에 적용할 수 있는 원동력이 되었다.


### 심층학습 (Deep Learning)

이제 딥러닝에 대해 간략히 알아보자. (아주 간략히)

인위적으로 지능을 구현하려는 **인공지능(Artificial Intelligence, AI)** 분야에는 다양한 하위분야가 있다. 생물의 원리를 모방하여 지능을 구현하려는 분야가 있고, 컴퓨터 안에서 지능을 구현하려는 시도가 있으며, 로보틱스(Robotics)와 같이 하드웨어와 밀접하게 발전되는 분야도 있다.

그 중 **컴퓨터(Machine)**을 이용하여 지능을 구현하려는 분야가 바로 요즘 자주 들리는 **기계학습(Machine Learning)**이며, 그 안에서도 다양한 방식의 알고리즘들이 있지만, 생물의 두뇌를 간략하게 모방하여 발전한 분야가 바로 **심층학습(Deep Learning)**이다. 

대부분의 딥러닝 응용연구에서 딥러닝은 좋은 패턴학습의 도구로 활용된다. 즉, 어떤 데이터 X와 Y의 쌍이 있을 때, 이들 사이에 존재하는 복잡하고 추상적인 패턴을 학습해내는 것이 딥러닝의 강점이라고 할 수 있다. 딥러닝은 머신러닝의 역사 초기에는 별로 주목을 받지 못했지만, 2000년대 이후 알고리즘의 발전과 방대한 계산을 뒷받침할 수 있는 GPU 등의 하드웨어의 발전으로 빛을 보게 되었다.

자, 그럼 이제 눈치를 채는 사람들이 있을 것이다.

1. **수십년 동안 DFT와 같은 계산과학 분야에는 데이터베이스가 축적되어 왔다**.
2. **최근 몇년 사이에 재조명 받기 시작한 딥러닝은 데이터가 충분히 있으면, 패턴학습을 잘 한다**.


계산과학 데이터베이스에는 일반적으로 다음과 같은 형식으로 데이터가 축적되어 있다. --> (물질의 구조 VS 물리적 성질)

즉, 물질의 구조정보를 X라고 하고, 이에 대응하는 물성정보를 Y라고 하면, X vs Y의 패턴학습을 딥러닝을 이용하여 학습한다면, 그 모델은 둘 사이에 존재하는 복잡한 비선형패턴을 학습하여, DFT에 비해 훨씬 빠른 계산시간 이점을 갖게 된다. 그리고 딥러닝을 공부해본 사람들은 알겠지만, 딥러닝 모델은 학습시킬 때 시간이 오래 걸리지만, 일단 학습된 모델이 새로운 데이터를 받아들여 그 예측을 출력하는데는 불과 몇초밖에 시간이 걸리지 않는다. 그리고 이러한 딥러닝 모델을 이용하여 방대한 가지수의 물질 탐색공간을 스캔할 수 있다면?? 굉장히 많은 물질조합에 대해 대략적인 물성예측을 할 수 있고, 이 중에서 특정한 물성조건을 만족하는 후보물질들만을 소수 채택하여 실제 실험에서 검증하는 단계로 넘어갈 수 있을 것이다! 

.. 그리고 이러한 개꿀 아이디어를 먼저 떠올리고 구현한 사람이 바로, 이 글에 최초로 언급된 논문의 저자라고 할 수 있다. (역시 무엇이든 최초가 중요하다 ㅠ.ㅠ)

물론 내가 위에서 설명한 것은 굉장히 단순화해서 설명한 것이다. 실제로는 어느정도 고체물리학이나 계산물리학에 대한 지식이 있어야 관련데이터를 가져오고 전처리할 수 있으며, 딥러닝분야에서도 GNN이라고 하는.. 컴퓨터비전이나 자연어처리에 비해 늦게 발전된 특수한 딥러닝 모델에 대한 지식, 그리고 torch 등의 딥러닝 라이브러리를 일정수준 이상으로 다룰 수 있어야 위의 연구를 구현할 수 있다.

CGCNN 이후 관련연구 논문이 많이 나왔으며, 내가 하는 연구도 그것의 연장선상에 있다고 할 수 있다.



## 2. 데이터에 관한 설명, 무엇에 관한 데이터인가?

Original CGCNN 논문을 보면, 저자는 Material Project라는 물질 데이터베이스에서 Perovskite 물질군 데이터를 가져와서 모델을 학습했다고 언급되고 있다. 

[Material Project](https://materialsproject.org/)에 접속하면 "Harnessing the power of supercomputing and state of the art electronic structure methods, the Materials Project provides open web-based access to computed information on known and predicted materials as well as powerful analysis tools to inspire and design novel materials." 이라는 문구가 눈에 들어온다.

간단히 말하자면, 지금까지 계산된 DFT 기반의 전자구조계산 결과들을 저장하고 있는 Web 기반, Open 데이터베이스이며 여러가지 분석 툴까지 제공한다고 한다.


![Material Project 1](https://user-images.githubusercontent.com/76824867/155843080-2e32c5de-a535-44be-931a-df6c26a18bea.PNG)

![Material Project 2](https://user-images.githubusercontent.com/76824867/155843078-3e14027b-74dd-4d97-b6a8-2b8983af9881.PNG)

기본적인 사용방법은 매우 간단하다.

1. 회원가입 후 로그인을 한다. (구글 아이디가 있다면 바로 로그인이 가능하다.)
2. 검색하고 싶은 적절한 화합물의 식을 입력한다. 예를 들면 SrTiO3라는 페로브스카이트의 한 종류를 입력해보자.

![Material Project 3](https://user-images.githubusercontent.com/76824867/155843217-3fb5c8a3-04bc-4977-9803-16cc81121c17.PNG)

3. 다음과 같이 동일한 화학식을 가졌지만, 세부적으로는 다른 다양한 계산결과들이 나온다.

![Material Project 4](https://user-images.githubusercontent.com/76824867/155843220-f1e15927-273a-4e83-8d5e-347d9db48be0.PNG)

4. mp-5229 라는 번호를 가진 물질에 대해 알고 싶다면, 해당 라인을 클릭한다. 그럼 다음과 같은 자료들이 나온다.

![Material Project 5](https://user-images.githubusercontent.com/76824867/155843221-2d6ecbeb-a625-4b40-b53a-8420729c330e.PNG)

![Material Project 6](https://user-images.githubusercontent.com/76824867/155843223-4bc63714-9a38-4f9a-8d4a-fdf62d24cfb4.PNG)

물질의 Unitcell 안에서의 구조와 여러가지 주요 물성정보들이 나옴을 알 수 있다. 밑으로 스크롤을 내리면, Density of State와 같은 DFT 계산에서 자주 다루어지는 중요한 정보들도 시각화되어 있음을 알 수 있다.

결국, 이 데이터베이스가 갖고 있는 것은 수십년간 연구되어 온 DFT 분야의 다양한 조건의 물질구조 및 그에 대응하는 여러 물리적 성질에 관한 정보임을 알 수 있다.

여기서는 자세히 다루지 않겠지만, Material Project는 이 데이터베이스에 대해 프로그래밍적으로 접근할 수 있는 API(python MPRester)를 제공한다. 해당 API를 사용하여 자신이 작업하는 환경에 수천, 수만개의 물질 데이터를 가져올 수 있고, 그것들을 전처리함으로써 연구의 첫 단계가 시작된다고 볼 수 있다.


## 3. 데이터전처리에 관한 설명, 어떻게 전처리해야 하는가?

자, 이제 Material Project 데이터베이스에서 데이터를 모두 받아왔다고 하자. 보통 물리학 분야에서 딥러닝을 적용하는 프로젝트는 제대로 된 데이터를 구하거나 직접 생성하는 단계에서 전체 프로젝트의 절반 가까운 시간이 소모되는 경우가 많다. 예를 들면, 계산과학 분야의 석학들이 이끄는 연구그룹에서 종종 발표되는 딥러닝 응용논문들을 보면, 연구원들이 자신들의 고도의 물리학적 지식을 동원하여, 실제 물리현상을 모방할 수 있는 유사 데이터를 직접 만들어 사용했음을 종종 볼 수 있다. 그런데 복잡한 물질현상을 모방할 수 있는 유사 데이터를 만드는 것이 쉬울까?.. 보통은 쉽지 않다. 그런 의미에서, 일단 데이터를 내가 직접 DFT로 생성할 필요가 없다는 것은 굉장한 행운이다. 

하지만 그래도 쉽지는 않다. 모든 딥러닝 프로젝트에서 가장 귀찮고, 지루하며, 그럼에도 불구하고 실수하면 전체 프로젝트의 성능에 지대한 영향을 미쳐서 방심해서는 안되는... **전처리(Preprocessing)** 단계가 남아있다.

여기서는 **결정구조(Crystal Structure)**를 가진, **고체물질**에 주로 한정하여 설명하도록 한다. 고체물질이 계산과학의 주요연구주제가 되는 이유는 고체의 **주기적 성질(Periodic Boundary Condition, PBC)**에 의해, 수학적으로 분석하기 용이하기 때문이다. (예를 들면, 주기적인 결정구조에 대해 **푸리에 변환(Fourier Transform)**을 하면, 그 결과 또한 주기적 성질을 띤다.) 또한 주변의 세상을 보면, 대부분의 안정된 물질들, 혹은 활용되는 물질들은 고체형태인 경우가 많아서 이기도 하다.

전처리 과정은 크게 2가지로 나눌 수 있을 것 같다.

1. 구조정보에 대한 전처리

구조정보에 대한 전처리는 결국 유닛셀 단위에서 정의된 여러 원자들의 좌표정보를 --> 그래프(Graph) 정보로 변환하는 과정이라고 할 수 있다.

여기서 그래프(Graph)라는 것은 무엇일까?.. 이산수학 또는 컴퓨터과학 분야에서 자주 연구되는 그래프는 흔히 노드(node)와 엣지(edge)로 이루어진 자료구조라고 볼 수 있다. 여기서 노드는 어떠한 객체를 의미하고, 엣지는 그러한 객체들 사이의 관계를 표현하는 개념이라고 볼 수 있다. 즉, 이 세상에 존재하는 여러 대상들이 온갖 관계는 기본적으로 그래프로 표현될 수 있다고 보면 된다.

그래프에 대한 깊은 설명은 나중에 다루기로 하고, 그럼 물질의 정보를 그래프 정보로 변환해야 한다는 것은 정확히 무슨 의미일까? 이는 결국 물질을 구성하는 원자(atom)를 노드로 간주하고, 원자 간의 상호작용을 엣지로 표현해야 한다는 것을 의미한다.

예를 들면, 물 분자 H20를 생각해보자. H2O는 원자 단위에서, 수소원자(H) 2개와 산소원자(O) 1개로 구성되어 있다. 따라서 이는 그래프의 노드 3개로 표현될 수 있을 것이다. 그리고, 중학교 때 배운 사실에 의하면, 2개의 H와 1개의 O는 수소결합이라는 특정한 결합을 하게 되고, 결합의 특수성에 의해 특정한 각도로 조금 기울어져서 위치하게 된다는 것도 알고 있다. 그렇다면 이러한 결합은 노드 사이의 엣지로 표현될 수 있다.

아마 물리학을 공부한 사람들이라면, 결국 엣지가 의미하는 것은 원자간의 힘(Force)가 아닐까? 라고 추측할 수 있을 것이다. 사실 그 말이 맞다. 하지만, 문제는.. 물질 안에 존재하는 온갖 종류의 복잡한 상호작용을 모두 제대로 고려하여 전처리하기란 매우 어렵다는 것이다!

원자 스케일에서 이루어지는 힘에 대해 조금만 떠올려보자. 일단 힘의 종류가 여러가지가 있다. 대충 기억해봐도 공유결합, 수소결합, 반데르발스 결합 같은 용어들이 떠오른다. 제대로 분석해서 들어가자면, 여러 원자들의 전자구조, 즉 오비탈(orbital)에 대해 알아야 하고 이들 사이의 상호작용이 어떻게 이루어지는가를 다 고려해야 할 것 같다. 그리고 그것은 이론적으로 매우 어렵다.

따라서 CGCNN의 저자는 (아마 그 전부터 관련분야의 연구원들이 공통적으로 그랬던 것 같지만) 힘이 아니라 거리를 엣지의 주요 정보로 표현한다.

즉, 물질 내부의 원자간에 온갖 복잡한 상호작용이 있다고 할지라도, 결국에는 그것은 원자간의 끌거나 밀어내는 힘으로 표현될 것이고, 그 영향력은 최종적으로 거리로 표현될 것이다! 라고 해석하는 관점이다.

이것은 문제를 상당히 간략하게 만드는 거의 유일한 전처리 방법이라고 본다. 

결과적으로 각각의 원자는 -> 원자노드(Atomic node)로 표현된다. 그리고 그들 사이의 거리(Distance)는 그래프의 엣지에 부여되는 일종의 가중치 (edge weight) 정보로 표현된다. 이후에, 각각의


2. 물성정보에 대한 전처리

물성정보에 대한 전처리는 사실 굉장히 간단하다. 

N개의 물질 정보가 있다고 하면, 그것들은 결국 다음과 같이 표현된다.

$$(X_1, Y_1), (X_2, Y_2), ... (X_i, Y_i)...$$

물성정보 Y만을 모으면, N개의 스칼라값이 나란히 있는 분포가 된다.

어떤 값들의 분포가 있을 때, 여기에 대해 정규화(Normalization)을 해서 사용하는 것은 머신러닝 프로젝트에서 흔히 보인다. CGCNN 저자는 간단한 정규화를 통해 평균이 0, 표준편차가 1인 분포를 만들어내고 사용했다.

대략 다음과 같다.

1. Y 데이터의 평균값을 구한다 -> Y.mean
2. Y 데이터의 표준편차를 구한다 -> Y.std
3. 정규화한다. -> Y = (Y - Y.mean) / Y.std 

이렇게 정규화를 하는 이유는.. 결국 최종적으로 딥러닝 모델이 수행하게 될 regression 문제에서, 값의 분포가 넓게 펼쳐져 있으면 학습이 어렵기 때문인 것으로 추측된다. Classification 문제와 다르게, regression 문제에서는 각각의 y 샘플들의 값에 치밀하게 근접하는 값을 추출하도록 모델의 가중치들이 보다 섬세하게 최적화될 필요가 있는데, 값의 분포가 넓을 경우, 학습이 어려워지게 될 것은 자명하다. 따라서 이런 정규화과정이 선행되었다.


## 4. 모델링에 관한 설명, 그래프 신경망(Graph Neural Network, GNN)이란 무엇인가?

이제 모델링에 관해 설명해보자.

잠깐 딥러닝에 관해 말하자면, 일반인들에게 딥러닝은 2016년 알파고와 이세돌의 대국을 통해 알려지기 시작했다고 볼 수 있다. 물론 딥러닝 열풍 이전에도 꾸준히 해당분야의 연구자들이 연구를 지속해왔지만, 확실히 다른 분야에서도 딥러닝 응용논문이 쏟아진 것은 알파고 이후 텐서플로우와 파이토치 등 각종 프레임워크의 발전이 영향을 주었다고 볼 수 있을 것이다.

인공지능 분야를 원래부터 공부하던 특정 전공분야(통계학, 컴퓨터공학 등)을 제외하면, 대부분의 비전공자 학부생들이 머신러닝을 공부하게 되면, 대체적으로 다음의 순서로 학습을 경험할 것이라 생각된다.

1. 일반적인 정형데이터에 대해 적용될 수 있는 고전적인 통계기반의 머신러닝 알고리즘들을 조금 배우고
2. 다양한 머신러닝 알고리즘들 중, 특별히 신경망 형태로 작동하는 딥러닝 모델에 대해 알게 될 것이고
3. 딥러닝 모델의 학습과정, Backpropagation 같은 것들을 배우고나서 CNN, RNN 등에 대해 배우게 될 것이다.
4. CNN 기반의 신경망 모델이 발전하여 컴퓨터비전(Computer Vision)이라는 분야를 석권하고 있고, RNN, LSTM 등이 발전하여 BERT, Transformer와 같은 모델들이 자연어처리(Natural Language Processing, NLP)에서 발전되고 있으며..
5. 맨날 신경망 훈련시켜 예측하는, Supervised learning에 질려 Unsupervised learning에서 클러스터링을 조금 공부하고나서
6. 새로운것에 목말라 GAN과 같은 생성모델링과 강화학습에 눈을 돌리게 될 것이다.

사실 2010년쯤부터 CV쪽 분야가 급격하게 발전하다가 발전이 조금 수렴되는 느낌이 있고 (어디까지나 비전공자 학부생들한테만), 그 이후에 자연어처리 분야가 바턴을 이어받아 급격하게 발전되다가 다시 조금 잠잠해진 감이 있었다. 

그러다가 2020년쯤부터, (실제로는 2017년이전부터도 논문들이 나왔지만) 딥러닝 커뮤니티에서 자주 언급되기 시작하는 새로운 신경망이 있었으니, 그것이 바로 GNN이었다.

### 그래서 GNN이란 무엇인가?

이전까지 신경망에 대해 공부한 사람들이라면, 다들 이미지 처리에 특화된 CNN이나 자연어처리에서 자주 쓰이는 RNN, LSTM 등의 모델들을 잘 알 것이다.

그런데 이런 모델들에는 몇 가지 전제가 있었다.

이미지, 자연어 모두 비정형 데이터인것은 맞지만, 결국 특정한 공간에서 하나의 벡터로 표현될 수 있었다. (이것이 불가능하다면, 자연어처리 분야의 워드 임베딩(Word Embedding)은 있을 수 없다.)

그런데, 우리가 이제부터 다루게 될 데이터는 조금 다르다. 기본적으로 물질의 구조정보는 그래프로 표현되는 것이 가장 자연스럽다. 따라서 그 정보를 학습해야 할 우리의 모델 또한, 그래프 정보를 Input으로 받아들일 수 있어야 한다. 그리고 여기서 조금 문제가 생기게 된다.

> Q. 그래프를 벡터로 표현할 수 있는가?

대부분의 머신러닝 모델들은 몇 가지 가정을 전제로 하고 있다. 바로 데이터의 Feature가 서로 독립이라는 것이다. 그러나 그래프는 이와 다르다. 그래프는 본질적으로 Irregular Domain (Non-Euclidean Space)에 존재하며, 데이터의 Feature들간의 독특한 관계(Relationship)가 존재한다. 따라서 이러한 관계를 잘 포착하는 적합한 방법이 필요했다. 

기존의 CNN, RNN 기반의 모델들은 이러한 기능이 없었으므로, Graph 정보 그 자체를 input으로 받아들일 수 있는 신경망인 GNN이 만들어지게 되었다.


