{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01. Original CGCNN code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOKMbufmCuxMHaBSJSdm4MR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Eihu0RK3gLfc"},"source":["# Google Drive Mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Av33EFHKf4CP","executionInfo":{"status":"ok","timestamp":1615178835114,"user_tz":-540,"elapsed":1903,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"fde7150c-b54c-4f43-fb3f-21e32e42c0af"},"source":["from google.colab import drive\r\n","drive.mount(\"/content/drive\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MYD0o8lf8O8","executionInfo":{"status":"ok","timestamp":1615178836038,"user_tz":-540,"elapsed":2552,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"bb145cb4-bf7e-420a-92eb-a2be3afcddbe"},"source":["cd drive/My Drive"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive'\n","/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zonjmw_Ff8RQ","executionInfo":{"status":"ok","timestamp":1615178836039,"user_tz":-540,"elapsed":2307,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"4f52c6c9-d48d-4beb-dd35-1e4873dceccc"},"source":["ls"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34m'읽을 예정인 논문 모음'\u001b[0m/  \u001b[01;34m'01. Backup Files'\u001b[0m/   \u001b[01;34mcgcnn\u001b[0m/      \u001b[01;34mGraphGAN\u001b[0m/\n","\u001b[01;34m'00. Github'\u001b[0m/             \u001b[01;34m'02. 데이터'\u001b[0m/         \u001b[01;34mCGCNN-HD\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OkAWr7lRf8TJ"},"source":["# CGCNN github clone"]},{"cell_type":"code","metadata":{"id":"ORT65vHff8Vj","executionInfo":{"status":"ok","timestamp":1615178836526,"user_tz":-540,"elapsed":1885,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["#!git clone https://github.com/txie-93/cgcnn"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IpyYXJJXgcQ3"},"source":["# Pymatgen Install"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JN9IqHeIf8Xs","executionInfo":{"status":"ok","timestamp":1615178840647,"user_tz":-540,"elapsed":5164,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}},"outputId":"49b74b20-0926-4ce2-c91e-942980f5b28a"},"source":["!pip install pymatgen==2020.11.11"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pymatgen==2020.11.11 in /usr/local/lib/python3.7/dist-packages (2020.11.11)\n","Requirement already satisfied: plotly>=4.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (4.14.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (2.23.0)\n","Requirement already satisfied: spglib>=1.9.9.44 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (1.16.1)\n","Requirement already satisfied: ruamel.yaml>=0.15.6 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (0.16.13)\n","Requirement already satisfied: monty>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (2021.3.3)\n","Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (1.1.5)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (2.5)\n","Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (3.1.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (1.7.1)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (1.6.1)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (1.19.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (0.8.9)\n","Requirement already satisfied: palettable>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from pymatgen==2020.11.11) (3.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.11.11) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.5.0->pymatgen==2020.11.11) (1.3.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.11.11) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.11.11) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.11.11) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pymatgen==2020.11.11) (2020.12.5)\n","Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.6->pymatgen==2020.11.11) (0.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.11.11) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.11.11) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.11.11) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pymatgen==2020.11.11) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pymatgen==2020.11.11) (2018.9)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.2->pymatgen==2020.11.11) (4.4.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from uncertainties>=3.1.4->pymatgen==2020.11.11) (0.16.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->pymatgen==2020.11.11) (1.2.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tf1o1CNYf8aD"},"source":["## cgcnn/cgcnn/data.py"]},{"cell_type":"code","metadata":{"id":"fYwlJYAUf8cI","executionInfo":{"status":"ok","timestamp":1615178845343,"user_tz":-540,"elapsed":1971,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["from __future__ import print_function, division\r\n","\r\n","import csv\r\n","import functools\r\n","import json\r\n","import os\r\n","import random\r\n","import warnings\r\n","\r\n","import numpy as np\r\n","import torch\r\n","from pymatgen.core.structure import Structure\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from torch.utils.data.dataloader import default_collate\r\n","from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeOJ8NQgf8eX","executionInfo":{"status":"ok","timestamp":1615178846311,"user_tz":-540,"elapsed":2613,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def get_train_val_test_loader(dataset, collate_fn = default_collate,\r\n","                              batch_size = 64, train_ratio = None,\r\n","                              val_ratio = 0.1, test_ratio = 0.1, return_test = False,\r\n","                              num_workers = 1, pin_memory = False, **kwargs):\r\n","    \"\"\"\r\n","    Utility function for dividing a dataset to train, val, test datasets.\r\n","    !!! The dataset needs to be shuffled before using the function !!!\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    dataset: torch.utils.data.Dataset\r\n","             The full dataset to be divided.\r\n","    collate_fn: torch.utils.data.DataLoader\r\n","    batch_size: int\r\n","    train_ratio: float\r\n","    val_ratio: float\r\n","    test_ratio: float\r\n","    return_test: bool\r\n","        Whether to return the test dataset loader. If False, the last test_size \r\n","        data will be hidden.\r\n","    num_workers: int\r\n","    pin_memory: bool\r\n","\r\n","    Returns\r\n","    -------\r\n","    train_loader: torch.utils.data.DataLoader\r\n","        DataLoader that random samples the training data.\r\n","    val_loader: torch.utils.data.DataLoader\r\n","        DataLoader that random samples the validation data.\r\n","    (test_loader): torch.utils.data.DataLoader\r\n","        DataLoader that random samples the test data, returns if\r\n","        return_test = True.\r\n","    \"\"\"\r\n","    total_size = len(dataset)\r\n","\r\n","    if train_ratio is None:\r\n","        assert val_ratio + test_ratio < 1\r\n","        train_ratio = 1 - val_ratio - test_ratio\r\n","        print('[Warning] train_ratio is None, using all training data.')\r\n","    else:\r\n","        assert train_ratio + val_ratio + test_ratio <= 1\r\n","    \r\n","    indices = list(range(total_size))\r\n","\r\n","    if kwargs['train_size']:\r\n","        train_size = kwargs['train_size']\r\n","    else:\r\n","        train_size = int(train_ratio * total_size)\r\n","\r\n","    if kwargs['test_size']:\r\n","        test_size = kwargs['test_size']\r\n","    else:\r\n","        test_size = int(test_ratio * total_size)\r\n","    \r\n","    if kwargs['val_size']:\r\n","        valid_size = kwargs['val_size']\r\n","    else:\r\n","        valid_size = int(val_ratio * total_size)\r\n","\r\n","    train_sampler = SubsetRandomSampler(indices[:train_size])\r\n","    val_sampler = SubsetRandomSampler(\r\n","        indices[-(valid_size + test_size):-test_size])\r\n","    \r\n","    if return_test:\r\n","        test_sampler = SubsetRandomSampler(indices[-test_size:])\r\n","\r\n","    train_loader = DataLoader(dataset, batch_size = batch_size,\r\n","                              sampler = train_sampler,\r\n","                              num_workers = num_workers,\r\n","                              collate_fn = collate_fn, pin_memory = pin_memory)\r\n","    val_loader = DataLoader(dataset, batch_size = batch_size,\r\n","                            sampler = val_sampler,\r\n","                            num_workers = num_workers,\r\n","                            collate_fn = collate_fn, pin_memory = pin_memory)\r\n","    if return_test:\r\n","        test_loader = DataLoader(dataset, batch_size = batch_size,\r\n","                                 sampler = test_sampler,\r\n","                                 num_workers = num_workers,\r\n","                                 collate_fn = collate_fn, pin_memory = pin_memory)\r\n","    if return_test:\r\n","        return train_loader, val_loader, test_loader\r\n","    else:\r\n","        return train_loader, val_loader \r\n","        "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ilp5BwOf8ga","executionInfo":{"status":"ok","timestamp":1615178846312,"user_tz":-540,"elapsed":1972,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def collate_pool(dataset_list):\r\n","    \"\"\"\r\n","    Collate a list of data and return a batch for predicting crystal properties.\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    dataset_list: list of tuples for each data point.\r\n","        (atom_fea, nbr_fea, nbr_fea_idx, target)\r\n","\r\n","        atom_fea: torch.Tensor shape (n_i, atom_fea_len)\r\n","        nbr_fea: torch.Tensor shape (n_i, M, nbr_fea_len)\r\n","        nbr_fea_idx: torch.LongTensor shape (n_i, M)\r\n","        target: torch.Tensor shape (1, )\r\n","        cif_id: str or int\r\n","\r\n","    Returns\r\n","    -------\r\n","    N = sum(n_i); N0 = sum(i)\r\n","\r\n","    batch_atom_fea: torch.Tensor shape (N, orig_atom_fea_len)\r\n","        Atom features from atom type\r\n","    batch_nbr_fea: torch.Tensor shape (N, M, nbr_fea_len)\r\n","        Bond features of each atom's M neighbors\r\n","    batch_nbr_fea_idx: torch.LongTensor shape (N, M)\r\n","        Indices of M neighbors of each atom\r\n","    crystal_atom_idx: list of torch.LongTensor of length N0\r\n","        Mapping from the crystal idx to atom idx\r\n","    target: torch.Tensor shape (N, 1)\r\n","        Target value for prediction\r\n","    batch_cif_ids: list\r\n","    \"\"\"\r\n","    batch_atom_fea, batch_nbr_fea, batch_nbr_fea_idx = [], [], []\r\n","    crystal_atom_idx, batch_target = [], []\r\n","    batch_cif_ids = []\r\n","    base_idx = 0\r\n","\r\n","    for i, ((atom_fea, nbr_fea, nbr_fea_idx), target, cif_id) in enumerate(dataset_list):\r\n","\r\n","        n_i = atom_fea.shape[0]  # number of atoms for this crystal\r\n","        \r\n","        batch_atom_fea.append(atom_fea)\r\n","        batch_nbr_fea.append(nbr_fea)\r\n","        batch_nbr_fea_idx.append(nbr_fea_idx + base_idx)\r\n","\r\n","        new_idx = torch.LongTensor(np.arange(n_i) + base_idx)\r\n","\r\n","        crystal_atom_idx.append(new_idx)\r\n","        batch_target.append(target)\r\n","        batch_cif_ids.append(cif_id)\r\n","\r\n","        base_idx += n_i\r\n","\r\n","    return (torch.cat(batch_atom_fea, dim = 0),\r\n","            torch.cat(batch_nbr_fea, dim = 0),\r\n","            torch.cat(batch_nbr_fea_idx, dim = 0),\r\n","            crystal_atom_idx), \\\r\n","            torch.stack(batch_target, dim = 0), \\\r\n","            batch_cif_ids\r\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ecpc7V9-f8id","executionInfo":{"status":"ok","timestamp":1615178846846,"user_tz":-540,"elapsed":1850,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class GaussianDistance(object):\r\n","    \"\"\"\r\n","    Expands the distance by Gaussian basis.\r\n","\r\n","    Unit: angstrom\r\n","    \"\"\"\r\n","    def __init__(self, dmin, dmax, step, var = None):\r\n","        \"\"\"\r\n","        Parameters\r\n","        ----------\r\n","        dmin: float\r\n","            Minimum interatomic distance\r\n","        dmax: float\r\n","            Maximum interatomic distance\r\n","        step: float\r\n","            Step size for the Gaussian filter\r\n","        \"\"\"\r\n","        assert dmin < dmax\r\n","        assert dmax - dmin > step\r\n","        self.filter = np.arange(dmin, dmax + step, step)\r\n","        if var is None:\r\n","            var = step\r\n","        self.var = var\r\n","\r\n","    def expand(self, distances):\r\n","        \"\"\"\r\n","        Apply Gaussian distances filter to a numpy distance array\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        distance: np.array shape n-d array\r\n","            A distance matrix of any shape\r\n","        \r\n","        Returns\r\n","        -------\r\n","        expanded_distance: shape (n+1)-d array\r\n","            Expanded distance matrix with the last dimension of length\r\n","            len(self.filter)\r\n","        \"\"\"\r\n","        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 / self.var**2)\r\n","        "],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KcIS5E2f8k0","executionInfo":{"status":"ok","timestamp":1615178847446,"user_tz":-540,"elapsed":1603,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class AtomInitializer(object):\r\n","    \"\"\"\r\n","    Base class for initializing the vector representation for atoms.\r\n","    !!! Use one AtomInitializer per dataset !!!\r\n","    \"\"\"\r\n","    def __init__(self, atom_types):\r\n","        self.atom_types = set(atom_types)\r\n","        self._embedding = {}\r\n","\r\n","    def get_atom_fea(self, atom_type):\r\n","        assert atom_type in self.atom_types\r\n","        return self._embedding[atom_type]\r\n","\r\n","    def load_state_dict(self, state_dict):\r\n","        self._embedding = state_dict\r\n","        self.atom_types = set(self._embedding.keys())\r\n","        self._decodedict = {idx: atom_type for atom_type, idx in \r\n","                            self._embedding.items()}\r\n","\r\n","    def state_dict(self):\r\n","        return self._embedding\r\n","\r\n","    def decode(self, idx):\r\n","        if not hasattr(self, '_decodedict'):\r\n","            self._decodedict = {idx: atom_type for atom_type, idx in \r\n","                                self._embedding.items()}\r\n","        return self._decodedict[idx]\r\n","        "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuuPh8URpLpk","executionInfo":{"status":"ok","timestamp":1615178848375,"user_tz":-540,"elapsed":1118,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class AtomCustomJSONInitializer(AtomInitializer):\r\n","    \"\"\"\r\n","    Initialize atom feature vectors using a JSON file, which is a python\r\n","    dictionary mapping from element number to a list representing the \r\n","    feature vector of the element.\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    elem_embedding_file: str\r\n","        The path to the .json file\r\n","    \"\"\"\r\n","    def __init__(self, elem_embedding_file):\r\n","        with open(elem_embedding_file) as f:\r\n","            elem_embedding = json.load(f)\r\n","        elem_embedding = {int(key): value for key, value\r\n","                          in elem_embedding.items()}\r\n","        atom_types = set(elem_embedding.keys())\r\n","        super(AtomCustomJSONInitializer, self).__init__(atom_types)\r\n","        for key, value in elem_embedding.items():\r\n","            self._embedding[key] = np.array(value, dtype = float)\r\n","            "],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"PP5V4e74qGhI","executionInfo":{"status":"ok","timestamp":1615180114952,"user_tz":-540,"elapsed":684,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class CIFData(Dataset):\r\n","    \"\"\"\r\n","    The CIFData dataset is a wrapper for a dataset where the crystal structures\r\n","    are stored in the form of CIF files. The dataset should have the following \r\n","    directory structure:\r\n","\r\n","    root_dir\r\n","    ├── id_prop.csv\r\n","    ├── atom_init.json\r\n","    ├── id0.cif\r\n","    ├── id1.cif\r\n","    ├── ...\r\n","\r\n","    id_prop.csv: a CSV file with two columns. The first column recodes a \r\n","    unique ID for each crystal, and the second column recodes the value of\r\n","    target property.\r\n","\r\n","    atom_init.json: a JSON file that stores the initialization vector for each\r\n","    element.\r\n","\r\n","    ID.cif: a CIF file that recodes the crystal structure, where ID is the\r\n","    unique ID for the crystal.\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    root_dir: str\r\n","        The path to the root directory of the dataset\r\n","    max_num_nbr: int\r\n","        The maximum number of neighbors while constructing the crystal graph\r\n","    radius: float\r\n","        The cutoff radius for searching neighbors\r\n","    dmin: float\r\n","        The minimum distance for constructing GaussianDistance\r\n","    step: float\r\n","        The step size for constructing GaussianDistance\r\n","    random_seed: int\r\n","        Random seed for shuffling the dataset\r\n","\r\n","    Returns\r\n","    -------\r\n","    atom_fea: torch.Tensor shape (n_i, atom_fea_len)\r\n","    nbr_fea: torch.Tensor shape (n_i, M, nbr_fea_len)\r\n","    nbr_fea_idx: torch.LongTensor shape (n_i, M)\r\n","    target: torch.Tensor shape (1, )\r\n","    cif_id: str or int\r\n","    \"\"\"\r\n","    def __init__(self, root_dir, max_num_nbr = 12, radius = 8, dmin = 0, step = 0.2,\r\n","                 random_seed = 123):\r\n","        self.root_dir = root_dir\r\n","        self.max_num_nbr, self.radius = max_num_nbr, radius\r\n","        assert os.path.exists(root_dir), 'root_dir does not exist!'\r\n","        id_prop_file = os.path.join(self.root_dir, 'id_prop.csv')\r\n","        assert os.path.exists(id_prop_file), 'id_prop.csv does not exist!'\r\n","        with open(id_prop_file) as f:\r\n","            reader = csv.reader(f)\r\n","            self.id_prop_data = [row for row in reader]\r\n","        random.seed(random_seed)\r\n","        random.shuffle(self.id_prop_data)\r\n","        atom_init_file = os.path.join(self.root_dir, 'atom_init.json')\r\n","        assert os.path.exists(atom_init_file), 'atom_init.json does not exist!'\r\n","        \r\n","        self.ari = AtomCustomJSONInitializer(atom_init_file)\r\n","        self.gdf = GaussianDistance(dmin = dmin, dmax = self.radius, step = step)\r\n","\r\n","    def __len__(self):\r\n","        return len(self.id_prop_data)\r\n","\r\n","    @functools.lru_cache(maxsize = None)  # Cache loaded structures\r\n","    def __getitem__(self, idx):\r\n","        cif_id, target = self.id_prop_data[idx]\r\n","        crystal = Structure.from_file(os.path.join(self.root_dir, cif_id + '.cif'))\r\n","\r\n","        atom_fea = np.vstack([self.ari.get_atom_fea(crystal[i].specie.number)\r\n","                              for i in range(len(crystal))])\r\n","        atom_fea = torch.Tensor(atom_fea)\r\n","\r\n","        all_nbrs = crystal.get_all_neighbors(self.radius, include_index = True)\r\n","        all_nbrs = [sorted(nbrs, key = lambda x: x[1]) for nbrs in all_nbrs]\r\n","\r\n","        nbr_fea_idx, nbr_fea = [], []\r\n","        for nbr in all_nbrs:\r\n","            if len(nbr) < self.max_num_nbr:\r\n","                warnings.warn('{} not find enough neighbors to build graph. '\r\n","                              'If it happens frequently, consider increase '\r\n","                              'radius.'.format(cif_id))\r\n","                nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) +\r\n","                                   [0] * (self.max_num_nbr - len(nbr)))\r\n","                nbr_fea.append(list(map(lambda x: x[1], nbr)) + \r\n","                               [self.radius + 1.] * (self.max_num_nbr - len(nbr)))\r\n","            else:\r\n","                nbr_fea_idx.append(list(map(lambda x: x[2],\r\n","                                            nbr[:self.max_num_nbr])))\r\n","                nbr_fea.append(list(map(lambda x: x[1], \r\n","                                        nbr[:self.max_num_nbr])))\r\n","                \r\n","        nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\r\n","        nbr_fea = self.gdf.expand(nbr_fea)\r\n","        atom_fea = torch.Tensor(atom_fea)\r\n","        nbr_fea = torch.Tensor(nbr_fea)\r\n","        nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\r\n","        target = torch.Tensor([float(target)])\r\n","\r\n","        return (atom_fea, nbr_fea, nbr_fea_idx), target, cif_id\r\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DszIiFEGO2PF"},"source":["## cgcnn/cgcnn/model.py"]},{"cell_type":"code","metadata":{"id":"rObMwG3pPSka","executionInfo":{"status":"ok","timestamp":1615180401393,"user_tz":-540,"elapsed":695,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["from __future__ import print_function, division\r\n","\r\n","import torch\r\n","import torch.nn as nn"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQoCS6ZRQLIE","executionInfo":{"status":"ok","timestamp":1615181220266,"user_tz":-540,"elapsed":705,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class ConvLayer(nn.Module):\r\n","    \"\"\"\r\n","    Convolutional operation on graphs\r\n","    \"\"\"\r\n","    def __init__(self, atom_fea_len, nbr_fea_len):\r\n","        \"\"\"\r\n","        Initialize ConvLayer.\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        atom_fea_len: int\r\n","            Number of atom hidden features.\r\n","        nbr_fea_len: int\r\n","            Number of bond features.\r\n","        \"\"\"\r\n","        super(ConvLayer, self).__init__()\r\n","        self.atom_fea_len = atom_fea_len\r\n","        self.nbr_fea_len = nbr_fea_len\r\n","        self.fc_full = nn.Linear(2 * self.atom_fea_len + self.nbr_fea_len,\r\n","                                 2 * self.atom_fea_len)\r\n","        self.sigmoid = nn.Sigmoid()\r\n","        self.softplus1 = nn.Softplus()\r\n","        self.bn1 = nn.BatchNorm1d(2 * self.atom_fea_len)\r\n","        self.bn2 = nn.BatchNorm1d(self.atom_fea_len)\r\n","        self.softplus2 = nn.Softplus()\r\n","\r\n","    def forward(self, atom_in_fea, nbr_fea, nbr_fea_idx):\r\n","        \"\"\"\r\n","        Forward pass\r\n","\r\n","        N: Total number of atoms in the batch\r\n","        M: Max number of neighbors\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        atom_in_fea: Variable(torch.Tensor) shape (N, atom_fea_len)\r\n","            Atom hidden features before convolution\r\n","        nbr_fea: Variable(torch.Tensor) shape (N, M, nbr_fea_len)\r\n","            Bond features of each atom's M neighbors\r\n","        nbr_fea_idx: torch.LongTensor shape (N, M)\r\n","            Indices of M neighbors of each atom\r\n","        \r\n","        Returns\r\n","        -------\r\n","        atom_out_fea: nn.Variable shape (N, atom_fea_len)\r\n","            Atom hidden features after convolution\r\n","        \"\"\"\r\n","        # TODO will there be problems with the index zero padding?\r\n","        N, M = nbr_fea_idx.shape\r\n","\r\n","        # convolution\r\n","        atom_nbr_fea = atom_in_fea[nbr_fea_idx, :]\r\n","        total_nbr_fea = torch.cat(\r\n","            [atom_in_fea.unsqueeze(1).expand(N, M, self.atom_fea_len),\r\n","             atom_nbr_fea, nbr_fea], dim = 2)\r\n","        \r\n","        total_gated_fea = self.fc_full(total_nbr_fea)\r\n","        total_gated_fea = self.bn1(total_gated_fea.view(\r\n","            -1, self.atom_fea_len * 2)).view(N, M, self.atom_fea_len * 2)\r\n","        \r\n","        nbr_filter, nbr_core = total_gated_fea.chunk(2, dim = 2)\r\n","        nbr_filter = self.sigmoid(nbr_filter)\r\n","        nbr_core = self.softplus1(nbr_core)\r\n","        nbr_sumed = torch.sum(nbr_filter * nbr_core, dim = 1)\r\n","        nbr_sumed = self.bn2(nbr_sumed)\r\n","        out = self.softplus2(atom_in_fea + nbr_sumed)\r\n","\r\n","        return out"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpwS5tclQLKT","executionInfo":{"status":"ok","timestamp":1615182764409,"user_tz":-540,"elapsed":711,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class CrystalGraphConvNet(nn.Module):\r\n","    \"\"\"\r\n","    Create a crystal graph convolutional neural network for predicting total\r\n","    material properties.\r\n","    \"\"\"\r\n","    def __init__(self, orig_atom_fea_len, nbr_fea_len,\r\n","                 atom_fea_len = 64, n_conv = 3, h_fea_len = 128, n_h = 1,\r\n","                 classification = False):\r\n","        \"\"\"\r\n","        Initialize CrystalGraphConvNet.\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        orig_atom_fea_len: int\r\n","            Number of atom features in the input.\r\n","        nbr_fea_len: int\r\n","            Number of bond features.\r\n","        atom_fea_len: int\r\n","            Number of hidden atom features in the convolutional layers\r\n","        n_conv: int\r\n","            Number of convolutional layers\r\n","        h_fea_len: int\r\n","            Number of hidden features after pooling\r\n","        n_h: int\r\n","            Number of hidden layers after pooling\r\n","        \"\"\"\r\n","        super(CrystalGraphConvNet, self).__init__()\r\n","        self.classification = classification \r\n","        self.embedding = nn.Linear(orig_atom_fea_len, atom_fea_len)\r\n","        self.convs = nn.ModuleList([ConvLayer(atom_fea_len = atom_fea_len,\r\n","                                              nbr_fea_len = nbr_fea_len)\r\n","                                              for _ in range(n_conv)])\r\n","        self.conv_to_fc = nn.Linear(atom_fea_len, h_fea_len)\r\n","        self.conv_to_fc_softplus = nn.Softplus()\r\n","\r\n","        if n_h > 1:\r\n","            self.fcs = nn.ModuleList([nn.Linear(h_fea_len, h_fea_len)\r\n","                                      for _ in range(n_h - 1)])\r\n","            self.softpluses = nn.ModuleList([nn.Softplus()\r\n","                                             for _ in range(n_h - 1)])\r\n","        \r\n","        if self.classification:\r\n","            self.fc_out = nn.Linear(h_fea_len, 2)\r\n","        else:\r\n","            self.fc_out = nn.Linear(h_fea_len, 1)\r\n","        \r\n","        if self.classification:\r\n","            self.logsoftmax = nn.LogSoftmax(dim = 1)\r\n","            self.dropout = nn.Dropout()\r\n","\r\n","    def forward(self, atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx):\r\n","        \"\"\"\r\n","        Forward pass\r\n","\r\n","        N: Total number of atoms in the batch\r\n","        M: Max number of neighbors\r\n","        N0: Total number of crystals in the batch\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        atom_fea: Variable(torch.Tensor) shape (N, orig_atom_fea_len)\r\n","            Atom features from atom type\r\n","        nbr_fea: Variable(torch.Tensor) shape (N, M, nbr_fea_len)\r\n","            Bond features of each atom's M neighbors\r\n","        nbr_fea_idx: torch.LongTensor shape (N, M)\r\n","            Indices of M neighbors of each atom\r\n","        crystal_atom_idx: list of torch.LongTensor of length N0\r\n","            Mapping from the crystal idx to atom idx\r\n","\r\n","        Returns\r\n","        -------\r\n","        prediction: nn.Variable shape (N, )\r\n","            Atom hidden features after convolution\r\n","        \"\"\"\r\n","        atom_fea = self.embedding(atom_fea)\r\n","        for conv_func in self.convs:\r\n","            atom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\r\n","        \r\n","        crys_fea = self.pooling(atom_fea, crystal_atom_idx)\r\n","        crys_fea = self.conv_to_fc(self.conv_to_fc_softplus(crys_fea))\r\n","        crys_fea = self.conv_to_fc_softplus(crys_fea)\r\n","\r\n","        if self.classification:\r\n","            crys_fea = self.dropout(crys_fea)\r\n","        \r\n","        if hasattr(self, 'fcs') and hasattr(self, 'softpluses'):\r\n","            for fc, softplus in zip(self.fcs, self.softpluses):\r\n","                crys_fea = softplus(fc(crys_fea))\r\n","        \r\n","        out = self.fc_out(crys_fea)\r\n","\r\n","        if self.classification:\r\n","            out = self.logsoftmax(out)\r\n","        \r\n","        return out\r\n","\r\n","    def pooling(self, atom_fea, crystal_atom_idx):\r\n","        \"\"\"\r\n","        Pooling the atom features to crystal features\r\n","\r\n","        N: Total number of atoms in the batch\r\n","        N0: Total number of crystals in the batch\r\n","\r\n","        Parameters\r\n","        ----------\r\n","        atom_fea: Variable(torch.Tensor) shape (N, atom_fea_len)\r\n","            Atom feature vectors of the batch\r\n","        crystal_atom_idx: list of torch.LongTensor of length N0\r\n","            Mapping from the crystal idx to atom idx\r\n","        \"\"\"\r\n","        assert sum([len(idx_map) for idx_map in crystal_atom_idx]) == \\\r\n","            atom_fea.data.shape[0]\r\n","        summed_fea = [torch.mean(atom_fea[idx_map], dim = 0, keepdim = True)\r\n","                      for idx_map in crystal_atom_idx]\r\n","        return torch.cat(summed_fea, dim = 0)\r\n"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZNlziprQLMj"},"source":["## cgcnn/main.py"]},{"cell_type":"code","metadata":{"id":"dIC9IIvpQLPN","executionInfo":{"status":"ok","timestamp":1615182952851,"user_tz":-540,"elapsed":674,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["import argparse\r\n","import os\r\n","import shutil\r\n","import sys\r\n","import time\r\n","import warnings\r\n","from random import sample\r\n","\r\n","import numpy as np\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","from sklearn import metrics\r\n","from torch.autograd import Variable\r\n","from torch.optim.lr_scheduler import MultiStepLR\r\n","\r\n","#from cgcnn.data import CIFData\r\n","#from cgcnn.data import collate_pool, get_train_val_test_loader\r\n","#from cgcnn.model import CrystalGraphConvNet"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1c38K7vQLRC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVnrCN7ZQLTQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SUUg2thQLXq","executionInfo":{"status":"ok","timestamp":1615183389454,"user_tz":-540,"elapsed":684,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class Normalizer(object):\r\n","    \"\"\" Normalize a Tensor and restore it later. \"\"\"\r\n","\r\n","    def __init__(self, tensor):\r\n","        \"\"\" tensor is taken as a sample to calculate the mean and std \"\"\"\r\n","        self.mean = torch.mean(tensor)\r\n","        self.std = torch.std(tensor)\r\n","\r\n","    def norm(self, tensor):\r\n","        return (tensor - self.mean) / self.std\r\n","    \r\n","    def denorm(self, normed_tensor):\r\n","        return normed_tensor * self.std + self.mean\r\n","\r\n","    def state_dict(self):\r\n","        return {'mean': self.mean, \r\n","                'std': self.std}\r\n","    \r\n","    def load_state_dict(self, state_dict):\r\n","        self.mean = state_dict['mean']\r\n","        self.std = state_dict['std']\r\n","        "],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEqjAABTQLaX","executionInfo":{"status":"ok","timestamp":1615183461091,"user_tz":-540,"elapsed":677,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def mae(prediction, target):\r\n","    \"\"\"\r\n","    Computes the mean absolute error between prediction and target\r\n","\r\n","    Parameters\r\n","    ----------\r\n","    prediction: torch.Tensor (N, 1)\r\n","    target: torch.Tensor (N, 1)\r\n","    \"\"\"\r\n","    return torch.mean(torch.abs(target - prediction))"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"cuE7P5BjQLcr","executionInfo":{"status":"ok","timestamp":1615183694434,"user_tz":-540,"elapsed":712,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def class_eval(prediction, target):\r\n","\r\n","    prediction = np.exp(prediction.numpy())\r\n","    target = target.numpy()\r\n","\r\n","    pred_label = np.argmax(prediction, axis = 1)\r\n","    target_label = np.squeeze(target)\r\n","\r\n","    if not target_label.shape:\r\n","        target_label = np.asarray([target_label])\r\n","    \r\n","    if prediction.shape[1] == 2:\r\n","        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\r\n","            target_label, pred_label, average = 'binary')\r\n","        auc_score = metrics.roc_auc_score(target_label, prediction[:, 1])\r\n","        accuracy = metrics.accuracy_score(target_label, pred_label)\r\n","    else:\r\n","        raise NotImplementedError\r\n","    return accuracy, precision, recall, fscore, auc_score"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzTzOAChQLfP","executionInfo":{"status":"ok","timestamp":1615183971167,"user_tz":-540,"elapsed":703,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["class AverageMeter(object):\r\n","    \"\"\" Computes and stores the average and current value \"\"\"\r\n","    \r\n","    def __init__(self):\r\n","        self.reset()\r\n","\r\n","    def reset(self):\r\n","        self.val = 0\r\n","        self.avg = 0\r\n","        self.sum = 0\r\n","        self.count = 0\r\n","\r\n","    def update(self, val, n = 1):\r\n","        self.val = val\r\n","        self.sum += val * n\r\n","        self.count += n\r\n","        self.avg = self.sum / self.count"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIKlzfNYQLhI","executionInfo":{"status":"ok","timestamp":1615184027366,"user_tz":-540,"elapsed":718,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\r\n","    torch.save(state, filename)\r\n","    if is_best:\r\n","        shutil.copyfile(filename, 'model_best.pth.tar')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"23ptS4xUQLll","executionInfo":{"status":"ok","timestamp":1615184125490,"user_tz":-540,"elapsed":647,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def adjust_learning_rate(optimizer, epoch, k):\r\n","    \"\"\" Sets the learning rate to the initial LR decayed by 10 every k epochs \"\"\"\r\n","    assert type(k) is int\r\n","    lr = args.lr * (0.1 ** (epoch // k))\r\n","    for param_group in optimizer.param_groups:\r\n","        param_group['lr'] = lr\r\n","        "],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnk3tRDyedts","executionInfo":{"status":"ok","timestamp":1615186561641,"user_tz":-540,"elapsed":716,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def train(train_loader, model, criterion, optimizer, epoch, normalizer):\r\n","\r\n","    batch_time = AverageMeter()\r\n","    data_time = AverageMeter()\r\n","    losses = AverageMeter()\r\n","\r\n","    if args.task == 'regression':\r\n","        mae_errors = AverageMeter()\r\n","    else:\r\n","        accuracies = AverageMeter()\r\n","        precisions = AverageMeter()\r\n","        recalls = AverageMeter()\r\n","        fscores = AverageMeter()\r\n","        auc_scores = AverageMeter()\r\n","    \r\n","    # switch to train mode\r\n","    model.train()\r\n","\r\n","    end = time.time()\r\n","\r\n","    for i, (input, target, _) in enumerate(train_loader):\r\n","\r\n","        # measure data loading time\r\n","        data_time.update(time.time() - end)\r\n","\r\n","        if args.cuda:\r\n","            input_var = (Variable(input[0].cuda(non_blocking = True)),\r\n","                         Variable(input[1].cuda(non_blocking = True)),\r\n","                         input[2].cuda(non_blocking = True),\r\n","                         [crys_idx.cuda(non_blocking = True) for crys_idx in input[3]])\r\n","        else:\r\n","            input_var = (Variable(input[0]),\r\n","                         Variable(input[1]),\r\n","                         input[2],\r\n","                         input[3])\r\n","        \r\n","        # normalize target\r\n","        if args.task == 'regression':\r\n","            target_normed = normalizer.norm(target)\r\n","        else:\r\n","            target_normed = target.view(-1).long()\r\n","        \r\n","        if args.cuda:\r\n","            target_var = Variable(target_normed.cuda(non_blocking = True))\r\n","        else:\r\n","            target_var = Variable(target_normed)\r\n","\r\n","        # compute output\r\n","        output = model(*input_var)\r\n","        loss = criterion(output, target_var)\r\n","\r\n","        # measure accuracy and record loss\r\n","        if args.task == 'regression':\r\n","            mae_error = mae(normalizer.denorm(output.data.cpu()), target)\r\n","            losses.update(loss.data.cpu(), target.size(0))\r\n","            mae_errors.update(mae_error, target.size(0))\r\n","        else:\r\n","            accuracy, precision, recall, fscore, auc_score = \\\r\n","                class_eval(output.data.cpu(), target)\r\n","            losses.update(loss.data.cpu().item(), target.size(0))\r\n","            accuracies.update(accuracy, target.size(0))\r\n","            precisions.update(precision, target.size(0))\r\n","            recalls.update(recall, target.size(0))\r\n","            fscores.update(fscore, target.size(0))\r\n","            auc_scores.update(auc_score, target.size(0))\r\n","\r\n","        # compute gradient and do SGD step\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","\r\n","        # measure elapsed time\r\n","        batch_time.update(time.time() - end)\r\n","        end = time.time()\r\n","\r\n","        if i % args.print_freq == 0:\r\n","            if args.task == 'regression':\r\n","                print('Epoch: [{0}][{1}/{2}]\\t'\r\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\r\n","                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\r\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\r\n","                      'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\r\n","                          epoch, i, len(train_loader), batch_time = batch_time,\r\n","                          data_time = data_time, loss = losses, mae_errors = mae_errors))\r\n","            else:\r\n","                print('Epoch: [{0}][{1}/{2}]\\t'\r\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\r\n","                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\r\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\r\n","                      'Accu {accu.val:.3f} ({accu.avg:.3f})\\t'\r\n","                      'Precision {prec.val:.3f} ({prec.avg:.3f})\\t'\r\n","                      'Recall {recall.val:.3f} ({recall.avg:.3f})\\t'\r\n","                      'F1 {f1.val:.3f} ({f1.avg:.3f})\\t'\r\n","                      'AUC {auc.val:.3f} ({auc.avg:.3f})'.format(\r\n","                          epoch, i, len(train_loader), batch_time = batch_time,\r\n","                          data_time = data_time, loss = losses, accu = accuracies,\r\n","                          prec = precisions, recall = recalls, f1 = fscores,\r\n","                          auc = auc_scores))\r\n"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"VevSZzu-fBKk","executionInfo":{"status":"ok","timestamp":1615188805884,"user_tz":-540,"elapsed":751,"user":{"displayName":"Hyoungsun Park","photoUrl":"","userId":"14179648673617368098"}}},"source":["def validate(val_loader, model, criterion, normalizer, test = False):\r\n","\r\n","    batch_time = AverageMeter()\r\n","    losses = AverageMeter()\r\n","\r\n","    if args.task == 'regression':\r\n","        mae_errors = AverageMeter()\r\n","    else:\r\n","        accuracies = AverageMeter()\r\n","        precisions = AverageMeter()\r\n","        recalls = AverageMeter()\r\n","        fscores = AverageMeter()\r\n","        auc_scores = AverageMeter()\r\n","    \r\n","    if test:\r\n","        test_targets = []\r\n","        test_preds = []\r\n","        test_cif_ids = []\r\n","\r\n","    # switch to evaluate mode\r\n","    model.eval()\r\n","\r\n","    end = time.time()\r\n","\r\n","    for i, (input, target, batch_cif_ids) in enumerate(val_loader):\r\n","\r\n","        if args.cuda:\r\n","            with torch.no_grad():\r\n","                input_var = (Variable(input[0].cuda(non_blocking = True)),\r\n","                             Variable(input[1].cuda(non_blocking = True)),\r\n","                             input[2].cuda(non_blocking = True),\r\n","                             [crys_idx.cuda(non_blocking = True) for crys_idx in input[3]])\r\n","        else:\r\n","            with torch.no_grad():\r\n","                input_var = (Variable(input[0]),\r\n","                             Variable(input[1]),\r\n","                             input[2],\r\n","                             input[3])\r\n","        if args.task == 'regression':\r\n","            target_normed = normalizer.norm(target)\r\n","        else:\r\n","            target_normed = target.view(-1).long()\r\n","\r\n","        if args.cuda:\r\n","            with torch.no_grad():\r\n","                target_var = Variable(target_normed.cuda(non_blocking = True))\r\n","        else:\r\n","            with torch.no_grad():\r\n","                target_var = Variable(target_normed)\r\n","        \r\n","        # compute output\r\n","        output = model(*input_var)\r\n","        loss = criterion(output, target_var)\r\n","\r\n","        # measure accuracy and record loss\r\n","        if args.task == 'regression':\r\n","            mae_error = mae(normalizer.denorm(output.data.cpu()), target)\r\n","            losses.update(loss.data.cpu().item(), target.size(0))\r\n","            mae_errors.update(mae_error, target.size(0))\r\n","\r\n","            if test:\r\n","                test_pred = normalizer.denorm(output.data.cpu())\r\n","                test_target = target\r\n","                test_preds += test_pred.view(-1).tolist()\r\n","                test_targets += test_target.view(-1).tolist()\r\n","                test_cif_ids += batch_cif_ids\r\n","        else:\r\n","            accuracy, precision, recall, fscore, auc_score = \\\r\n","                class_eval(output.data.cpu(), target)\r\n","            \r\n","            losses.update(loss.data.cpu().item(), target.size(0))\r\n","            accuracies.update(accuracy, target.size(0))\r\n","            precisions.update(precision, target.size(0))\r\n","            recalls.update(recall, target.size(0))\r\n","            fscores.update(fscore, target.size(0))\r\n","            auc_scores.update(auc_score, target.size(0))\r\n","\r\n","            if test:\r\n","                test_pred = torch.exp(output.data.cpu())\r\n","                test_target = target\r\n","                assert test_pred.shape[1] == 2\r\n","                test_preds += test_pred[:, 1].tolist()\r\n","                test_targets += test_target.view(-1).tolist()\r\n","                test_cif_ids += batch_cif_ids\r\n","        \r\n","        # measure elapsed time\r\n","        batch_time.update(time.time() - end)\r\n","        end = time.time()\r\n","\r\n","        if i % args.print_freq == 0:\r\n","            if args.task == 'regression':\r\n","                print('Test: [{0}/{1}]\\t'\r\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\r\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\r\n","                      'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\r\n","                          i, len(val_loader), batch_time = batch_time, loss = losses,\r\n","                          mae_errors = mae_errors))\r\n","            else:\r\n","                print('Test: [{0}/{1}]\\t'\r\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\r\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\r\n","                      'Accu {accu.val:.3f} ({accu.avg:.3f})\\t'\r\n","                      'Precision {prec.val:.3f} ({prec.avg:.3f})\\t'\r\n","                      'Recall {recall.val:.3f} ({recall.avg:.3f})\\t'\r\n","                      'F1 {f1.val:.3f} ({f1.avg:.3f})\\t'\r\n","                      'AUC {auc.val:.3f} ({auc.avg:.3f})'.format(\r\n","                          i, len(val_loader), batch_time = batch_time, loss = losses,\r\n","                          accu = accuracies, prec = precisions, recall = recalls,\r\n","                          f1 = fscores, auc = auc_scores))                \r\n","    if test:\r\n","        star_label = '**'\r\n","        import csv\r\n","        with open('test_results.csv', 'w') as f:\r\n","            writer = csv.writer(f)\r\n","\r\n","            for cif_id, target, pred in zip(test_cif_ids, test_targets, test_preds):\r\n","                writer.writerow((cif_id, target, pred))\r\n","    else:\r\n","        star_label = '*'\r\n","\r\n","\r\n","    if args.task == 'regression':\r\n","        print(' {star} MAE {mae_errors.avg:.3f}'.format(star = star_label,\r\n","                                                        mae_errors = mae_errors))\r\n","        return mae_errors.avg\r\n","    else:\r\n","        print(' {star} AUC {auc.avg:.3f}'.format(star = star_label,\r\n","                                                 auc = auc_scores))\r\n","        return auc_scores.avg\r\n","        "],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2G1BO2HfBNS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2LSBiGifBPg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dr5hffOcfBSJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyoHk87xfBUk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FangHpF8fBXU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mErxWvUmfBaL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PH8UBadofBcq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgI3VnZ2fBe0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XuJrs3UXfBhc"},"source":[""],"execution_count":null,"outputs":[]}]}